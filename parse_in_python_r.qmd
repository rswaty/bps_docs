---
title: "parse in python"
format: html
editor: visual
---

## Basics

-   need to 'break apart' bps docs into parts so we can reassemble in a database
-   sections are denoted in multiple ways, mostly by **bold** which is a problem as there are bold sections in table
-   some ideas
    -   try to remove all tables then parse by bold-tables removed with Python

## python to remove tables

```{python}

# Specify the input and output directories
input_directory = 'test_docs/two_docs'
output_directory = 'no_tables2'



import os
from docx import Document

def remove_tables_from_docx(input_file, output_file):
    # Load the document
    doc = Document(input_file)
    
    # Find all tables in the document
    tables = doc.tables
    
    # Iterate over tables in reverse order and delete them
    for table in reversed(tables):
        table._element.getparent().remove(table._element)
    
    # Save the modified document to the output file
    doc.save(output_file)
    print(f"Tables removed and saved to {output_file}")

def process_directory(input_directory, output_directory):
    # Create the output directory if it doesn't exist
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)
    
    # Iterate over all files in the input directory
    for filename in os.listdir(input_directory):
        # Process only .docx files
        if filename.endswith('.docx'):
            input_file = os.path.join(input_directory, filename)
            output_file = os.path.join(output_directory, filename)
            remove_tables_from_docx(input_file, output_file)



# Process the directory
process_directory(input_directory, output_directory)




```

**Looks like it worked!**

## Try to extract most **Bold** components to a dataframe

Components:

Vegetation Type Map Zones Model Splits or Lumps Geographic Range Biophysical Site Description Vegetation Description Disturbance Description Scale Description Adjacency or Identification Concerns Issues or Problems Native Uncharacteristic Conditions Comments

## Get specific sections in R from table-less docs

Having to ignore these sections:

-   BpS Dominant and Indicator Species
-   Fire Frequency
-   Succession Classes

Will need to add in References

```{r}
library(officer)
library(dplyr)
library(stringr)

# Define the directory path and sections
directory_path <- "no_tables2/"
sections <- c("Vegetation Type",
              "Map Zones",
              "Model Splits or Lumps",
              "Geographic Range",
              "Biophysical Site Description",
              "Vegetation Description",
              "Disturbance Description",
              "Scale Description",
              "Adjacency or Identification Concerns",
              "Issues or Problems",
              "Native Uncharacteristic Conditions",
              "Comments")

# Function to extract sections from a Word document
extract_sections <- function(doc_path, sections) {
  doc <- read_docx(doc_path)
  paragraphs <- docx_summary(doc)
  
  content_list <- lapply(sections, function(section) {
    section_index <- which(paragraphs$text == section)
    if (length(section_index) == 0) return(NA)
    content <- ""
    i <- section_index + 1
    while (i <= nrow(paragraphs)) {
      if (paragraphs$text[i] %in% sections) break
      if (str_detect(paragraphs$text[i], "Succession Classes")) break
      if (str_detect(paragraphs$text[i], "BpS Dominant and Indicator Species")) {
        while (i <= nrow(paragraphs) && !paragraphs$text[i] %in% sections) {
          i <- i + 1
        }
        break
      }
      if (str_detect(paragraphs$text[i], "Fire Frequency")) {
        while (i <= nrow(paragraphs) && !paragraphs$text[i] %in% sections) {
          i <- i + 1
        }
        break
      }
      content <- paste(content, paragraphs$text[i], sep = "\n")
      i <- i + 1
    }
    content <- trimws(content)  # Trim leading/trailing whitespace
    if (content == "") return(NA)  # Return NA if the section is empty
    return(content)
  })
  
  names(content_list) <- sections
  content_list <- as.data.frame(content_list)
  content_list$document <- basename(doc_path)
  return(content_list)
}

# Get all docx files in the directory
doc_paths <- list.files(directory_path, pattern = "\\.docx$", full.names = TRUE)

# Extract data from each document
data_list <- lapply(doc_paths, function(doc_path) {
  extract_sections(doc_path, sections)
})

# Combine the data into a single dataframe
df <- bind_rows(data_list)

# Move 'document' column to the first position
df <- df %>% select(document, everything())

# Print the dataframe
print(df)


```

Looks pretty good!

## Create r-markdown for each row

```{r}
library(dplyr)
library(stringr)
library(rmarkdown)

# Sample dataframe (you should replace this with your actual dataframe)
# df <- ...

# Function to create an R Markdown file for each row
create_rmd_file <- function(row, headers, file_path) {
  lines <- c("---",
             "title: 'Document'",
             "output: html_document",
             "---",
             "")
  
  for (header in headers) {
    section_title <- paste("##", header)
    section_content <- row[[header]]
    if (!is.na(section_content) && section_content != "") {
      lines <- c(lines, section_title, section_content, "")
    }
  }
  
  writeLines(lines, con = file_path)
}

# Directory to save the R Markdown files
output_dir <- "output_rmds"
dir.create(output_dir, showWarnings = FALSE)

# Create an R Markdown file for each row in the dataframe
for (i in 1:nrow(df)) {
  row <- df[i, ]
  file_name <- paste0("document_", i, ".Rmd")
  file_path <- file.path(output_dir, file_name)
  create_rmd_file(row, names(df), file_path)
}

```
